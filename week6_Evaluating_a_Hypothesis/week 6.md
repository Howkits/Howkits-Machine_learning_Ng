# week 6

[toc]

## 1 学习算法评估

最小化训练集误差，计算测试集误差

训练集、验证集、测试集：60% 20% 20%

Cross Validation交叉验证 

模型选择：多项式次数  选择交叉验证集误差最小的系数 应用到测试集上->避免了使用测试集进行系数选择



## 2 偏差和方差

欠拟合：训练集与验证集误差都很大->高误差

过拟合：训练集误差小，验证集误差大->高方差



正则化：$\lambda$过小过拟合，过大欠拟合



学习曲线：

随着训练集样本数量增大，偏差增大；交叉验证集偏差减小->趋向于一个定值

（高偏差）->模型极限，再怎么增大样本数量都不会改善效果了

（高方差）->增大数据量能改善效果



## 3 各种改善学习算法性能的方法

获取更多训练样本->高方差

尝试使用更少的特征->高方差

更多的特征->高偏差

多项式特征->高偏差

增大减小$\lambda$->改善欠拟合与过拟合（对应高误差与高方差）



## 4 神经网络拟合

大型网络，使用正则化解决过拟合

确定隐藏层数量要建立不同的模型对比，默认一层

