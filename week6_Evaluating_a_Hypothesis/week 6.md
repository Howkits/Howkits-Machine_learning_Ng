# week 6

[toc]

## 1 学习算法评估

最小化训练集误差，计算测试集误差

训练集、验证集、测试集：60% 20% 20%

Cross Validation交叉验证 

模型选择：多项式次数  选择交叉验证集误差最小的系数 应用到测试集上->避免了使用测试集进行系数选择



## 2 偏差和方差

欠拟合：训练集与验证集误差都很大->高误差

过拟合：训练集误差小，验证集误差大->高方差



正则化：$\lambda$过小过拟合，过大欠拟合



学习曲线：

随着训练集样本数量增大，偏差增大；交叉验证集偏差减小->趋向于一个定值

（高偏差）->模型极限，再怎么增大样本数量都不会改善效果了

（高方差）->增大数据量能改善效果



## 3 各种改善学习算法性能的方法

获取更多训练样本->高方差

尝试使用更少的特征->高方差

更多的特征->高偏差

多项式特征->高偏差

增大减小$\lambda$->改善欠拟合与过拟合（对应高误差与高方差）



## 4 神经网络拟合

大型网络，使用正则化解决过拟合

确定隐藏层数量要建立不同的模型对比，默认一层



## 5 系统设计问题

垃圾邮件分类器：

如何构建特征x?->根据关键词是否出现构建特征向量

如何提高精度?

​	-> 收集带量数据->如何获取大量数据？->故意将一个邮箱泄露给垃圾邮件发送者

​	->复杂特征（基于邮件地址主题信息）（基于内容）

​	->开发复杂算法检测拼写错误

_头脑风暴列出各种提高精度的办法_

从简单算法开始

测试，验证（学习曲线）

不要过早优化、不要直觉

## 6 误差分析

查看错误分类规律->短处、新的特征

人工分类那些错分的样本

量化评估



## 7 设定误差度量值

偏斜类（skewed classes）的问题：

正反例数量差距太大

查准率（precison）=true positive/predicted positive(true p+false p)

召回率（recall）=true p/actual p(true p+false neg)

真阳\阴性、假阳\阴性

对较少的类设为1



权衡查准率和召回率：

根据目标确定分类0、1的临界值

高->高查准低召回

低->低查准高召回



不同临界值模型如何比较？->F1值=$2{\frac{PR}{P+R}}$



## 8 大数据集

数据集越大效果越好？

->数据集比参数规模还大->不容易过拟合

->特征要有足够信息准确预测结果