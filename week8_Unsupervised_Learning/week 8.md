# week 8

[toc]

## 1 聚类

**介绍**

无监督学习

市场分割、社交网络分析、组织计算集群、天文数据分析

**K-Means算法**

step1 集群分类，将各个点分给质心

step2 重新确定质心并移动

可能会有质心根本就没有分配到点，说明分类多了，删去

非良好分离聚类，点聚集非常密集

**优化目标**
$$
J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_K)=\frac{1}{m}\sum_{i=1}^{m}{||x^{(i)}}-\mu_{c^{(i)}}||^2
$$
$\min J$

step1 就是在最小化代价函数，固定$\mu$优化$c$

step2 固定$c$优化$\mu$

**随机初始化**

随机选K个样本作为初始质心->比较随机，效果可能不好，陷入局部最优

->多次运行K-Means，选取代价最小的（K=2-10，效果较好）

**选择聚类数目K**

手动！->模棱两可

肘部法则，选择不同的K，比较代价函数->仍然模棱两可

按目的确定K



## 2 降维

**动机**

* *数据压缩*：去冗余、数据表示不同了（直角坐标系上的点放到一条直线上表示（2d->1d）、空间中的点投影到一个平面（3d->2d））

* *数据可视化*：高维数据降到2或3维进行可视化->PCA

**PCA**

* *描述*：寻找具有最小投影误差平方的投影平面

特征规范化+均值归一化->特征均值为0

降到K维，需要寻找K个方向的向量，由这些向量张成的空间（span）->投影到K维平面

与回归不同，最小化的距离不同，目的也不同（预测）

* *算法*

1. 数据预处理（特征缩放/均值标准化）
2. 计算协方差矩阵$\Sigma$
3. 计算$\Sigma$特征向量:$\tt[U,S,V]=svd(Sigma)$->取U的前K个特征向量组成新的矩阵Uk
4. $\tt z=U_k^T*x$ 

* *应用*

1. 从压缩表示中重构

   $\tt z\approx x'=U_k*x$

2. 如何选择k

   最小化平均平方投影误差

   数据总变差（数值变化差的总和）数据平方和均值->总的来看，训练样本距离零向量\原点多远

   以上两个值的比不超过1%->保留了99%的差异性

   计算$1-\frac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}}$  ->尽量覆盖了所有的奇异值

3. 建议（加速学习算法）

   仅在训练集上

   糟糕应用：防止过拟合->使用正则化

   先使用原始数据进行训练