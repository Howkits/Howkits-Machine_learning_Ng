# week 10

[toc]

## 1 大数据集梯度下降

**随机梯度下降法**

梯度下降法也叫批量梯度下降（batch gradient descent)

随机梯度下降只考虑一个样本

1. 所有样本重新排列，shuffle
2. 更新

扫描所有样本，逐个样本拟合

更快

**mini-batch梯度下降**

介于上面两者之间

矢量化

**随机梯度下降收敛**

每1000个样本计算这1000个cost的平均值

动态学习率

## 2 进阶主题

**在线学习**

用户较多，数据理论上无限

对正在变化的用户偏好进行调适

预测点击率

类似随机梯度下降

**MapReduce与数据并行**

单机多核

Hadoop

